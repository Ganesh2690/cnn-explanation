{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"pWN1xA1XPwbY","executionInfo":{"status":"ok","timestamp":1697717556956,"user_tz":-330,"elapsed":4012,"user":{"displayName":"Ganesh Gotur","userId":"13388785542701095067"}}},"outputs":[],"source":["from keras.datasets import imdb"]},{"cell_type":"code","source":["vocabulary_size = 5000\n","(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n","print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYN2aGERP1v6","outputId":"cc441b92-347d-497f-c2b5-cb913fb0f304","executionInfo":{"status":"ok","timestamp":1697717659621,"user_tz":-330,"elapsed":5729,"user":{"displayName":"Ganesh Gotur","userId":"13388785542701095067"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17464789/17464789 [==============================] - 1s 0us/step\n","Loaded dataset with 25000 training samples, 25000 test samples\n"]}]},{"cell_type":"markdown","source":["The X_train variable will contain a list of lists where each inner list represents a movie review, but the words in the reviews are represented as integers corresponding to their rank in the top 5,000 most frequent words in the dataset.\n","\n","For example, X_train[0] might look something like this:\n","\n","\n","[1, 14, 22, 16, 43, 530, 973, 1622, ...]\n","Each integer in the list corresponds to a specific word in the review, and the integers are used as tokens to represent words."],"metadata":{"id":"v0V7RZtQQK_i"}},{"cell_type":"code","source":["print('---review---')\n","print(X_train[6])\n","print('---label---')\n","print(y_train[6])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zUqPCDmEP2fy","outputId":"59533290-349c-45b8-dc80-3aa53aa5e879","executionInfo":{"status":"ok","timestamp":1697717660140,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ganesh Gotur","userId":"13388785542701095067"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["---review---\n","[1, 2, 365, 1234, 5, 1156, 354, 11, 14, 2, 2, 7, 1016, 2, 2, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 2, 2, 1117, 1831, 2, 5, 4831, 26, 6, 2, 4183, 17, 369, 37, 215, 1345, 143, 2, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 2, 2, 63, 271, 6, 196, 96, 949, 4121, 4, 2, 7, 4, 2212, 2436, 819, 63, 47, 77, 2, 180, 6, 227, 11, 94, 2494, 2, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 2, 99, 76, 23, 2, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]\n","---label---\n","1\n"]}]},{"cell_type":"markdown","source":["You can use the dictionary returned by imdb.get_word_index() to map the review back to the original words.\n"],"metadata":{"id":"rD1w-iBQQTgU"}},{"cell_type":"code","source":["word2id = imdb.get_word_index()\n","id2word = {i: word for word, i in word2id.items()}\n","print('---review with words---')\n","print([id2word.get(i, ' ') for i in X_train[6]])\n","print('---label---')\n","print(y_train[6])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oYviXhpqP5f1","outputId":"30ee7992-590d-47e2-acb6-cc8648b1434c","executionInfo":{"status":"ok","timestamp":1697717664242,"user_tz":-330,"elapsed":1387,"user":{"displayName":"Ganesh Gotur","userId":"13388785542701095067"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n","1641221/1641221 [==============================] - 0s 0us/step\n","---review with words---\n","['the', 'and', 'full', 'involving', 'to', 'impressive', 'boring', 'this', 'as', 'and', 'and', 'br', 'villain', 'and', 'and', 'need', 'has', 'of', 'costumes', 'b', 'message', 'to', 'may', 'of', 'props', 'this', 'and', 'and', 'concept', 'issue', 'and', 'to', \"god's\", 'he', 'is', 'and', 'unfolds', 'movie', 'women', 'like', \"isn't\", 'surely', \"i'm\", 'and', 'to', 'toward', 'in', \"here's\", 'for', 'from', 'did', 'having', 'because', 'very', 'quality', 'it', 'is', 'and', 'and', 'really', 'book', 'is', 'both', 'too', 'worked', 'carl', 'of', 'and', 'br', 'of', 'reviewer', 'closer', 'figure', 'really', 'there', 'will', 'and', 'things', 'is', 'far', 'this', 'make', 'mistakes', 'and', 'was', \"couldn't\", 'of', 'few', 'br', 'of', 'you', 'to', \"don't\", 'female', 'than', 'place', 'she', 'to', 'was', 'between', 'that', 'nothing', 'and', 'movies', 'get', 'are', 'and', 'br', 'yes', 'female', 'just', 'its', 'because', 'many', 'br', 'of', 'overly', 'to', 'descent', 'people', 'time', 'very', 'bland']\n","---label---\n","1\n"]}]},{"cell_type":"markdown","source":["Maximum review length"],"metadata":{"id":"lieZielwQV0g"}},{"cell_type":"code","source":["print('Maximum review length: {}'.format(\n","len(max((X_train + X_test), key=len))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F5xKx18pQQ16","outputId":"cb239c58-37a7-45a9-f9aa-2b047517d8b0","executionInfo":{"status":"ok","timestamp":1697717668837,"user_tz":-330,"elapsed":580,"user":{"displayName":"Ganesh Gotur","userId":"13388785542701095067"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum review length: 2697\n"]}]},{"cell_type":"markdown","source":["**Pad Sequences**\n","\n","Limit the maximum review length to max_words by truncating longer reviews and padding shorter reviews with a null value.\n","\n","Neural networks require fixed-size inputs. However, text data, such as sentences or documents, can vary in length. Padding ensures that all input sequences have the same length, making them compatible with neural network models."],"metadata":{"id":"yc-UqPmNQYap"}},{"cell_type":"code","source":["# from keras.preprocessing import sequence\n","from tensorflow.keras.utils import pad_sequences\n","max_words = 500\n","X_train = pad_sequences(X_train, maxlen=max_words)\n","X_test = pad_sequences(X_test, maxlen=max_words)"],"metadata":{"id":"x8cJUyovQXrf","executionInfo":{"status":"ok","timestamp":1697717673011,"user_tz":-330,"elapsed":785,"user":{"displayName":"Ganesh Gotur","userId":"13388785542701095067"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from keras import Sequential\n","from keras.layers import Embedding, LSTM, Dense, Dropout\n","embedding_size=32\n","model=Sequential()\n","model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n","model.add(LSTM(100))\n","model.add(Dense(1, activation='sigmoid'))\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ryMq4QhqQgSs","outputId":"a8155264-8890-446a-aaff-aa8d03d883b8","executionInfo":{"status":"ok","timestamp":1697717675943,"user_tz":-330,"elapsed":738,"user":{"displayName":"Ganesh Gotur","userId":"13388785542701095067"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 500, 32)           160000    \n","                                                                 \n"," lstm (LSTM)                 (None, 100)               53200     \n","                                                                 \n"," dense (Dense)               (None, 1)                 101       \n","                                                                 \n","=================================================================\n","Total params: 213301 (833.21 KB)\n","Trainable params: 213301 (833.21 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["model.compile(loss='binary_crossentropy',\n","             optimizer='adam',\n","             metrics=['accuracy'])"],"metadata":{"id":"Dka7VCGDQ41f","executionInfo":{"status":"ok","timestamp":1697717682766,"user_tz":-330,"elapsed":3,"user":{"displayName":"Ganesh Gotur","userId":"13388785542701095067"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["batch_size = 64\n","num_epochs = 2\n","X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n","X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n","model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YKUifnWuQ9AF","outputId":"a4a9b635-6e7c-4825-e3b4-490184a761cb","executionInfo":{"status":"ok","timestamp":1697718248665,"user_tz":-330,"elapsed":563544,"user":{"displayName":"Ganesh Gotur","userId":"13388785542701095067"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","390/390 [==============================] - 282s 713ms/step - loss: 0.4801 - accuracy: 0.7617 - val_loss: 0.2774 - val_accuracy: 0.9062\n","Epoch 2/2\n","390/390 [==============================] - 281s 722ms/step - loss: 0.3222 - accuracy: 0.8619 - val_loss: 0.5957 - val_accuracy: 0.6562\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x79819a705c90>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["scores = model.evaluate(X_test, y_test, verbose=0)\n","print('Test accuracy:', scores[1])"],"metadata":{"id":"Pf4ETRoAQ-Iy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697719211996,"user_tz":-330,"elapsed":83129,"user":{"displayName":"Ganesh Gotur","userId":"13388785542701095067"}},"outputId":"51a182be-e2c7-4a5c-95b0-256222237e1e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy: 0.7129999995231628\n"]}]}]}